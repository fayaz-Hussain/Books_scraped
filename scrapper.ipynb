{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d45969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "import time \n",
    "import random\n",
    "from selenium.webdriver.chrome.options import Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31fbd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "headers= {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23e44771",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_numbers = {\n",
    "    'One': 1,\n",
    "    'Two': 2,\n",
    "    'Three': 3,\n",
    "    'Four': 4,\n",
    "    'Five': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb7e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_book_data(book,page_url):\n",
    "    time.sleep(random.uniform(2,3))\n",
    "    \n",
    "    title = book.h3.a['title']\n",
    "    link = book.h3.a['href']\n",
    "    price = float(book.find('p', class_='price_color').text.strip('Â£'))\n",
    "\n",
    "    rating = book.p['class']\n",
    "    rating_number = word_to_numbers.get(rating[1], 0)\n",
    "    stock = book.find('p', class_='instock availability').text.strip()\n",
    "\n",
    "    nested_page = urljoin(page_url,link)\n",
    "\n",
    "    res = requests.get(nested_page,headers)\n",
    "    nested_soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "    table = nested_soup.find_all('td')\n",
    "    description_tag = nested_soup.find('div', id='product_description')\n",
    "    if description_tag:\n",
    "        description = description_tag.find_next_sibling('p').text.strip()\n",
    "    else:\n",
    "        description = \"No description\"\n",
    "\n",
    "    return {\n",
    "        'Title': title,\n",
    "        'Price': price,\n",
    "        'Rating': rating_number,\n",
    "        'upc' : table[0].text,\n",
    "        'stock' : table[5].text.strip('In stock ( available)'),\n",
    "        'Link': link,\n",
    "        'description': description\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e676b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books(base_url):\n",
    "    dataset = []\n",
    "    current = base_url\n",
    "    page_num = 0\n",
    "\n",
    "    while current:\n",
    "        page_num += 1\n",
    "        print(f\"Scraping Page: {page_num}\")\n",
    "\n",
    "        response = requests.get(current,headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        books = soup.find_all('article', class_='product_pod')\n",
    "        for book in books:\n",
    "            data = extract_book_data(book,current)\n",
    "            dataset.append(data)\n",
    "\n",
    "        next_btn = soup.find('li', class_='next')\n",
    "        if next_btn:\n",
    "            next_url = next_btn.a['href']\n",
    "            current = urljoin(current, next_url)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f33bf641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page: 1\n",
      "Scraping Page: 2\n",
      "Scraping Page: 3\n",
      "Scraping Page: 4\n",
      "Scraping Page: 5\n",
      "Scraping Page: 6\n",
      "Scraping Page: 7\n",
      "Scraping Page: 8\n",
      "Scraping Page: 9\n",
      "Scraping Page: 10\n",
      "Scraping Page: 11\n",
      "Scraping Page: 12\n",
      "Scraping Page: 13\n",
      "Scraping Page: 14\n",
      "Scraping Page: 15\n",
      "Scraping Page: 16\n",
      "Scraping Page: 17\n",
      "Scraping Page: 18\n",
      "Scraping Page: 19\n",
      "Scraping Page: 20\n",
      "Scraping Page: 21\n",
      "Scraping Page: 22\n",
      "Scraping Page: 23\n",
      "Scraping Page: 24\n",
      "Scraping Page: 25\n",
      "Scraping Page: 26\n",
      "Scraping Page: 27\n",
      "Scraping Page: 28\n",
      "Scraping Page: 29\n",
      "Scraping Page: 30\n",
      "Scraping Page: 31\n",
      "Scraping Page: 32\n",
      "Scraping Page: 33\n",
      "Scraping Page: 34\n",
      "Scraping Page: 35\n",
      "Scraping Page: 36\n",
      "Scraping Page: 37\n",
      "Scraping Page: 38\n",
      "Scraping Page: 39\n",
      "Scraping Page: 40\n",
      "Scraping Page: 41\n",
      "Scraping Page: 42\n",
      "Scraping Page: 43\n",
      "Scraping Page: 44\n",
      "Scraping Page: 45\n",
      "Scraping Page: 46\n",
      "Scraping Page: 47\n",
      "Scraping Page: 48\n",
      "Scraping Page: 49\n",
      "Scraping Page: 50\n",
      "Scraping completed and data saved to 'output/books_data.csv'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    BASE_URL = \"https://books.toscrape.com/\"\n",
    "    books_data = scrape_books(BASE_URL)\n",
    "\n",
    "    # Save to Excel\n",
    "    df = pd.DataFrame(books_data)\n",
    "    df.to_csv(\"D:/Projects/web_scrapping/project/output/books_data.csv\", index=False)\n",
    "    print(\"Scraping completed and data saved to 'output/books_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc65da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
